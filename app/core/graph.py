# app/core/graph.py
from langgraph.graph import StateGraph, END
from .state import CSPEState
from .nodes import (
    extract_entities,
    analyze_deadline_criterion,
    analyze_quality_criterion,
    analyze_object_criterion,
    analyze_documents_criterion,
    make_final_decision,
    analyze_all_criteria_parallel
)
import logging

logger = logging.getLogger(__name__)

def should_continue_after_extraction(state: CSPEState) -> str:
    """D√©termine si on peut continuer apr√®s l'extraction d'entit√©s"""
    if state.get("error_message"):
        logger.error(f"Erreur d√©tect√©e: {state['error_message']}")
        return "error"
    
    # V√©rifier qu'on a au moins quelques entit√©s extraites
    extracted_applicant = state.get("extracted_applicant")
    extracted_dates = state.get("extracted_dates", {})
    
    if not extracted_applicant and not any(extracted_dates.values()):
        logger.warning("Extraction d'entit√©s insuffisante")
        return "insufficient_data"
    
    return "continue"

def should_continue_after_analysis(state: CSPEState) -> str:
    """D√©termine si on peut faire la d√©cision finale apr√®s les analyses"""
    if state.get("error_message"):
        return "error"
    
    # V√©rifier qu'on a au moins 3 analyses sur 4
    analyses = [
        state.get("deadline_analysis"),
        state.get("quality_analysis"),
        state.get("object_analysis"),
        state.get("documents_analysis")
    ]
    
    valid_analyses = sum(1 for analysis in analyses if analysis and not analysis.get("error"))
    
    if valid_analyses < 3:
        logger.warning(f"Seulement {valid_analyses}/4 analyses valides")
        return "insufficient_analysis"
    
    return "continue"

def create_cspe_workflow() -> StateGraph:
    """Cr√©e le workflow LangGraph pour l'analyse CSPE"""
    
    # Cr√©er le graphe avec l'√©tat CSPE
    workflow = StateGraph(CSPEState)
    
    # ===== AJOUT DES N≈íUDS =====
    
    # N≈ìud d'extraction d'entit√©s
    workflow.add_node("extract_entities", extract_entities)
    
    # N≈ìuds d'analyse des crit√®res (peuvent √™tre ex√©cut√©s en parall√®le)
    workflow.add_node("analyze_deadline", analyze_deadline_criterion)
    workflow.add_node("analyze_quality", analyze_quality_criterion)
    workflow.add_node("analyze_object", analyze_object_criterion)
    workflow.add_node("analyze_documents", analyze_documents_criterion)
    
    # Alternative: analyse parall√®le des 4 crit√®res
    workflow.add_node("analyze_all_parallel", analyze_all_criteria_parallel)
    
    # N≈ìud de d√©cision finale
    workflow.add_node("make_decision", make_final_decision)
    
    # N≈ìuds de gestion d'erreurs
    workflow.add_node("handle_extraction_error", handle_extraction_error)
    workflow.add_node("handle_analysis_error", handle_analysis_error)
    
    # ===== CONFIGURATION DU FLUX =====
    
    # Point d'entr√©e: extraction d'entit√©s
    workflow.set_entry_point("extract_entities")
    
    # Apr√®s extraction: v√©rifier si on peut continuer
    workflow.add_conditional_edges(
        "extract_entities",
        should_continue_after_extraction,
        {
            "continue": "analyze_all_parallel",  # Utilise l'analyse parall√®le pour plus d'efficacit√©
            "insufficient_data": "handle_extraction_error",
            "error": "handle_extraction_error"
        }
    )
    
    # Alternative: flux s√©quentiel (plus lent mais plus robuste)
    # workflow.add_edge("extract_entities", "analyze_deadline")
    # workflow.add_edge("analyze_deadline", "analyze_quality")  
    # workflow.add_edge("analyze_quality", "analyze_object")
    # workflow.add_edge("analyze_object", "analyze_documents")
    # workflow.add_edge("analyze_documents", "make_decision")
    
    # Apr√®s analyse parall√®le: d√©cision finale
    workflow.add_conditional_edges(
        "analyze_all_parallel",
        should_continue_after_analysis,
        {
            "continue": "make_decision",
            "insufficient_analysis": "handle_analysis_error",
            "error": "handle_analysis_error"
        }
    )
    
    # Fin du workflow apr√®s d√©cision
    workflow.add_edge("make_decision", END)
    
    # Gestion d'erreurs m√®ne √† la fin
    workflow.add_edge("handle_extraction_error", END)
    workflow.add_edge("handle_analysis_error", END)
    
    return workflow

# ===== N≈íUDS DE GESTION D'ERREURS =====

async def handle_extraction_error(state: CSPEState) -> dict:
    """G√®re les erreurs d'extraction d'entit√©s"""
    logger.error("‚ùå Gestion d'erreur d'extraction")
    
    error_message = state.get("error_message", "Erreur inconnue lors de l'extraction")
    
    return {
        "final_classification": "IRRECEVABLE", 
        "final_justification": f"Impossible d'analyser le document: {error_message}",
        "final_confidence": 0.0,
        "is_review_required": True,
        "critical_issues": ["Erreur technique", "Document illisible ou malform√©"],
        "analysis_summary": {
            "total_criteria": 4,
            "compliant_criteria": 0,
            "average_confidence": 0.0,
            "error": error_message
        }
    }

async def handle_analysis_error(state: CSPEState) -> dict:
    """G√®re les erreurs d'analyse des crit√®res"""
    logger.error("‚ùå Gestion d'erreur d'analyse")
    
    error_message = state.get("error_message", "Erreur lors de l'analyse des crit√®res")
    
    # Compter les analyses r√©ussies
    analyses = [
        state.get("deadline_analysis"),
        state.get("quality_analysis"),
        state.get("object_analysis"), 
        state.get("documents_analysis")
    ]
    
    successful_analyses = sum(1 for analysis in analyses if analysis and not analysis.get("error"))
    
    return {
        "final_classification": "IRRECEVABLE",
        "final_justification": f"Analyse incompl√®te ({successful_analyses}/4 crit√®res analys√©s): {error_message}",
        "final_confidence": 0.0,
        "is_review_required": True,
        "critical_issues": ["Erreur technique", "Analyse incompl√®te"],
        "analysis_summary": {
            "total_criteria": 4,
            "compliant_criteria": 0,
            "average_confidence": 0.0,
            "successful_analyses": successful_analyses,
            "error": error_message
        }
    }

# ===== CR√âATION DU WORKFLOW COMPIL√â =====

def create_compiled_workflow():
    """Cr√©e et compile le workflow pour utilisation"""
    try:
        workflow = create_cspe_workflow()
        compiled = workflow.compile()
        logger.info("‚úÖ Workflow CSPE compil√© avec succ√®s")
        return compiled
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la compilation du workflow: {e}")
        raise

# Instance du workflow compil√© (singleton)
compiled_workflow = None

def get_compiled_workflow():
    """Retourne l'instance compil√©e du workflow (singleton)"""
    global compiled_workflow
    if compiled_workflow is None:
        compiled_workflow = create_compiled_workflow()
    return compiled_workflow

# ===== FONCTIONS UTILITAIRES =====

async def execute_cspe_analysis(document_id: str, document_content: str) -> dict:
    """Fonction principale pour ex√©cuter une analyse CSPE compl√®te"""
    logger.info(f"üöÄ D√©but de l'analyse CSPE pour le document {document_id}")
    
    # √âtat initial
    initial_state = CSPEState(
        document_id=document_id,
        document_content=document_content,
        extracted_dates=None,
        extracted_applicant=None,
        deadline_analysis=None,
        quality_analysis=None,
        object_analysis=None,
        documents_analysis=None,
        final_classification=None,
        final_justification=None,
        final_confidence=None,
        is_review_required=True,
        error_message=None
    )
    
    try:
        # Obtenir le workflow compil√©
        workflow = get_compiled_workflow()
        
        # Ex√©cuter le workflow
        final_state = await workflow.ainvoke(initial_state)
        
        logger.info(f"‚úÖ Analyse CSPE termin√©e pour le document {document_id}")
        logger.info(f"üìä R√©sultat: {final_state.get('final_classification', 'UNKNOWN')}")
        
        return final_state
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution de l'analyse: {e}", exc_info=True)
        return {
            **initial_state,
            "final_classification": "IRRECEVABLE",
            "final_justification": f"Erreur syst√®me lors de l'analyse: {str(e)}",
            "final_confidence": 0.0,
            "is_review_required": True,
            "error_message": str(e)
        }

def get_workflow_graph_visualization():
    """Retourne une repr√©sentation du graphe pour debugging/visualisation"""
    try:
        workflow = create_cspe_workflow()
        return {
            "nodes": [
                "extract_entities",
                "analyze_deadline", 
                "analyze_quality",
                "analyze_object", 
                "analyze_documents",
                "analyze_all_parallel",
                "make_decision",
                "handle_extraction_error",
                "handle_analysis_error"
            ],
            "edges": [
                ("extract_entities", "analyze_all_parallel"),
                ("analyze_all_parallel", "make_decision"),
                ("make_decision", "END")
            ],
            "conditional_edges": [
                ("extract_entities", ["continue", "insufficient_data", "error"]),
                ("analyze_all_parallel", ["continue", "insufficient_analysis", "error"])
            ]
        }
    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration de la visualisation: {e}")
        return {"error": str(e)}